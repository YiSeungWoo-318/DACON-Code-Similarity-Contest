{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from code_function import preprocess_script, make_dataset, reduction_dataset,indentation\n",
    "from sklearn.model_selection import train_test_split , KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8affce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "problem_folders = glob(\"D:/code_preprocessing/clean/*.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba308f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_folders = glob(\"D:/code_preprocessing/executable/*.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465c2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(problem_folders):\n",
    "    preproc_scripts = []\n",
    "    problem_nums = []\n",
    "    for problem_folder in tqdm(problem_folders):\n",
    "        problem_num = os.path.basename(problem_folder).split(\".\")[0]\n",
    "        with open(problem_folder, \"rt\", encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            preproc_scripts.append(text)\n",
    "        problem_nums.append(problem_num)\n",
    "    df = pd.DataFrame(data = {'code':preproc_scripts, 'problem_script':problem_nums})\n",
    "    df['problem_num'] = df['problem_script'].apply(lambda x: x.split(\"_\")[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3602d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45101/45101 [03:55<00:00, 191.50it/s]\n"
     ]
    }
   ],
   "source": [
    "df = make_df(problem_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8754834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (922 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "df['tokens'] = df['code'].apply(tokenizer.tokenize)\n",
    "df['len'] = df['tokens'].apply(len)\n",
    "df['problem_num'] = df['problem_script'].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ed77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "global train_df\n",
    "global valid_df\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=33)\n",
    "\n",
    "for e, (train_index, test_index) in enumerate(skf.split(df, df['problem_num'])):\n",
    "    if e==0:\n",
    "        train_df, valid_df = df.iloc[train_index], df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb9ae105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40590/40590 [00:58<00:00, 689.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4511/4511 [00:24<00:00, 181.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def aug_list(df):\n",
    "    aug_train = []\n",
    "    aug_label = []\n",
    "    for t in tqdm(df.problem_script):\n",
    "        lf = f\"D:/code_preprocessing/executable/{t}.py\"\n",
    "        if os.path.exists(lf):\n",
    "            with open(lf, \"rt\", encoding = 'utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                relines = []\n",
    "                for line in lines:\n",
    "                    if \"sys.stdout = open(\" in line:\n",
    "                        continue\n",
    "                    if \"from unittest.mock import patch\" in line:\n",
    "                        continue\n",
    "                    if line.startswith(\"for FFF in\"):\n",
    "                        continue\n",
    "                    if \"with patch('builtins.input') as input_mock:\" in line:\n",
    "                        continue\n",
    "                    if \"input_mock.side_effect = FFF\" in line:\n",
    "                        continue\n",
    "                    if \"print('GOODJOBANDSUCCESS')\" in line:\n",
    "                        continue\n",
    "                    if \"sys.stdout.close()\" in line:\n",
    "                        continue\n",
    "                    else:\n",
    "                        relines.append(line)\n",
    "                relines = indentation(relines)\n",
    "                aug_train.append(relines)\n",
    "                aug_label.append(t)\n",
    "    aug = pd.DataFrame({\"code\":aug_train, \"problem_script\":aug_label})\n",
    "    aug['problem_num'] = aug['problem_script'].apply(lambda x: x.split(\"_\")[0])\n",
    "    return aug\n",
    "\n",
    "aug_train = aug_list(train_df)\n",
    "aug_valid = aug_list(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f47ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "aug_train['tokens'] = aug_train['code'].apply(tokenizer.tokenize)\n",
    "aug_train['len'] = aug_train['tokens'].apply(len)\n",
    "\n",
    "aug_valid['tokens'] = aug_valid['code'].apply(tokenizer.tokenize)\n",
    "aug_valid['len'] = aug_valid['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18401700",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = train_df[train_df['len']>2048]\n",
    "train_df = train_df[train_df[\"len\"] <= 2048]\n",
    "add_df[\"code\"] = add_df['code'].apply(lambda x :\" \".join(x.split(\" \")[-2048:]))\n",
    "train_df = pd.concat([train_df, add_df], ignore_index=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "add_df = valid_df[valid_df['len']>2048]\n",
    "valid_df = valid_df[valid_df[\"len\"] <= 2048]\n",
    "add_df[\"code\"] = add_df['code'].apply(lambda x :\" \".join(x.split(\" \")[-2048:]))\n",
    "# valid = pd.concat([valid_df, add_df], ignore_index=True) #코드실수함\n",
    "valid_df = pd.concat([valid_df, add_df], ignore_index=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de530074",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = train_df[train_df['len']>1026]\n",
    "train_df = train_df[train_df[\"len\"] <= 1026]\n",
    "add_df[\"code\"] = add_df['code'].apply(lambda x :\" \".join(x.split(\" \")[-1026:]))\n",
    "train_df = pd.concat([train_df, add_df], ignore_index=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "add_df = valid_df[valid_df['len']>1026]\n",
    "valid_df = valid_df[valid_df[\"len\"] <= 1026]\n",
    "add_df[\"code\"] = add_df['code'].apply(lambda x :\" \".join(x.split(\" \")[-1026:]))\n",
    "# valid = pd.concat([valid_df, add_df], ignore_index=True) #코드실수함\n",
    "valid_df = pd.concat([valid_df, add_df], ignore_index=True)\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "790c4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = aug_train[aug_train['len']>2048]\n",
    "aug_train = aug_train[aug_train[\"len\"] <= 2048]\n",
    "aug_train[\"code\"] = aug_train['code'].apply(lambda x :\" \".join(x.split(\" \")[-2048:]))\n",
    "aug_train = pd.concat([aug_train, add_df], ignore_index=True)\n",
    "aug_train = aug_train.reset_index(drop=True)\n",
    "\n",
    "add_df = aug_valid[aug_valid['len']>2048]\n",
    "aug_valid = aug_valid[aug_valid[\"len\"] <= 2048]\n",
    "add_df[\"code\"] = add_df['code'].apply(lambda x :\" \".join(x.split(\" \")[-2048:]))\n",
    "aug_valid = pd.concat([aug_valid, add_df], ignore_index=True)\n",
    "aug_valid = aug_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b39b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version1\n",
    "train_code = []\n",
    "for name, code in zip(train_df[\"problem_script\"], train_df[\"code\"]):\n",
    "#     if os.path.exists(f\"D:/open/executable/{name}.txt\"):\n",
    "#         temp = open(f\"D:/open/executable/{name}.txt\", \"r\").read()\n",
    "    if os.path.exists(f\"D:/code_preprocessing/executable/{name}.txt\"):\n",
    "        temp = open(f\"D:/code_preprocessing/executable/{name}.txt\", \"r\").read()\n",
    "        temp = temp.replace('GOODJOBANDSUCCESS', ' ')\n",
    "        temp = temp.replace(\"**START**\", \" \")\n",
    "        temp = temp[:100]\n",
    "        code = code +\"\\n\" + temp\n",
    "        train_code.append(code)\n",
    "    \n",
    "    else:\n",
    "        train_code.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6caa4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version2\n",
    "train_code = []\n",
    "for name, code in zip(train_df[\"problem_script\"], train_df[\"code\"]):\n",
    "#     if os.path.exists(f\"D:/open/executable/{name}.txt\"):\n",
    "#         temp = open(f\"D:/open/executable/{name}.txt\", \"r\").read()\n",
    "    if (os.path.exists(f\"D:/code_preprocessing/executable/{name}.txt\")) and \\\n",
    "        (os.path.exists(f\"D:/code_preprocessing/executable2/{name}.txt\")) and \\\n",
    "        (os.path.exists(f\"D:/code_preprocessing/executable3/{name}.txt\")):\n",
    "        temp = open(f\"D:/code_preprocessing/executable/{name}.txt\", \"r\").read()\n",
    "        temp = temp.replace('GOODJOBANDSUCCESS', ' ')\n",
    "        temp = temp.replace(\"**START**\", \" \")\n",
    "        temp = temp[:100]\n",
    "        temp2 =  open(f\"D:/code_preprocessing/executable2/{name}.txt\", \"r\").read()\n",
    "        temp2 = temp2[:100]\n",
    "        temp3 =  open(f\"D:/code_preprocessing/executable3/{name}.txt\", \"r\").read()\n",
    "        temp3 = temp3[:100]\n",
    "        code = code +\"\\n\" + temp +\"\\n\" + temp2 + \"\\n\" + temp3\n",
    "        train_code.append(code)\n",
    "    elif (os.path.exists(f\"D:/code_preprocessing/executable/{name}.txt\")):\n",
    "        temp = open(f\"D:/code_preprocessing/executable/{name}.txt\", \"r\").read()\n",
    "        temp = temp.replace('GOODJOBANDSUCCESS', ' ')\n",
    "        temp = temp.replace(\"**START**\", \" \")\n",
    "        temp = temp[:100]\n",
    "        code = code +\"\\n\" + temp \n",
    "        train_code.append(code)\n",
    "    else:\n",
    "        train_code.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8bbbabee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40590/40590 [05:51<00:00, 115.42it/s]\n"
     ]
    }
   ],
   "source": [
    "#version3\n",
    "train_code = []\n",
    "no_print = []\n",
    "for name, code in tqdm(zip(train_df[\"problem_script\"], train_df[\"code\"]), total=len(train_df[\"code\"])):\n",
    "    if len(code) > 200:\n",
    "        temp = code.split(\"\\n\")    \n",
    "        temp_list = []\n",
    "        for t in temp:\n",
    "            s = t.strip()\n",
    "            if s.startswith(\"print\"):\n",
    "                continue\n",
    "            else:\n",
    "                temp_list.append(t)\n",
    "        temp_result = \"\\n\".join(temp_list)\n",
    "        if temp_result:\n",
    "            no_print.append(temp_result)\n",
    "        else:\n",
    "            no_print.append(code)\n",
    "    else:\n",
    "        no_print.append(code)\n",
    "    \n",
    "    if (os.path.exists(f\"D:/code_preprocessing/executable/{name}.txt\")) and \\\n",
    "        (os.path.exists(f\"D:/code_preprocessing/executable2/{name}.txt\")) and \\\n",
    "        (os.path.exists(f\"D:/code_preprocessing/executable3/{name}.txt\")):\n",
    "        temp = open(f\"D:/code_preprocessing/executable/{name}.txt\", \"r\").read()\n",
    "        temp = temp.replace('GOODJOBANDSUCCESS', ' ')\n",
    "        temp = temp.replace(\"**START**\", \" \")\n",
    "        temp = temp[:100]\n",
    "        temp2 =  open(f\"D:/code_preprocessing/executable2/{name}.txt\", \"r\").read()\n",
    "        temp2 = temp2[:100]\n",
    "        temp3 =  open(f\"D:/code_preprocessing/executable3/{name}.txt\", \"r\").read()\n",
    "        temp3 = temp3[:100]\n",
    "        code2 = aug_train[aug_train[\"problem_script\"]==name][\"code\"].values[0]\n",
    "        if code2 = aug_train[aug_train[\"problem_script\"]==name][\"code\"].values[0]:\n",
    "            code2 = code2 +\"\\n\" + temp +\"\\n\" + temp2 + \"\\n\" + temp3\n",
    "            train_code.append(code2)\n",
    "        else:\n",
    "            code = code +\"\\n\" + temp +\"\\n\" + temp2 + \"\\n\" + temp3\n",
    "            train_code.append(code)\n",
    "    elif (os.path.exists(f\"D:/code_preprocessing/executable/{name}.txt\")):\n",
    "        temp = open(f\"D:/code_preprocessing/executable/{name}.txt\", \"r\").read()\n",
    "        temp = temp.replace('GOODJOBANDSUCCESS', ' ')\n",
    "        temp = temp.replace(\"**START**\", \" \")\n",
    "        temp = temp[:100]\n",
    "        code2 = aug_train[aug_train[\"problem_script\"]==name][\"code\"].values\n",
    "        if code2:\n",
    "            code2 = code2 +\"\\n\" + temp \n",
    "            train_code.append(code2)\n",
    "        else:\n",
    "            code = code +\"\\n\" + temp \n",
    "            train_code.append(code)\n",
    "    else:\n",
    "        train_code.append(code)\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1dc95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"code_\"] = train_code\n",
    "# train_df[\"code_no\"] = no_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b011173",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = train_df[[\"code\", \"problem_num\"]]\n",
    "train_df2 = train_df[[\"code_\", \"problem_num\"]]\n",
    "# train_df3 = train_df[[\"code_no\", \"problem_num\"]]\n",
    "train_df2.columns = [\"code\", \"problem_num\"]\n",
    "# train_df3.columns = [\"code\", \"problem_num\"]\n",
    "# train_df = pd.concat([train_df1, train_df2, train_df3], ignore_index=True)\n",
    "train_df = pd.concat([train_df1, train_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e83635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1, random_state=103).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6821c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1, random_state=20220609).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4489c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.code = train_df.code.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b6dfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates(\"code\")\n",
    "train_df = train_df.sample(frac=1, random_state=2022).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "249ccd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_fest_dataset(train_df, tokenizer):\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    from itertools import combinations\n",
    "    import random\n",
    "    codes = train_df['code'].to_list()\n",
    "    problems = train_df['problem_num'].unique().tolist()\n",
    "    problems.sort()\n",
    "\n",
    "    tokenized_corpus = [tokenizer.tokenize(code) for code in codes]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    total_positive_pairs = []\n",
    "    total_negative_pairs = []\n",
    "\n",
    "    for problem in tqdm(problems):\n",
    "        solution_codes = train_df[train_df['problem_num'] == problem]['code']\n",
    "        ppl = solution_codes.to_list()\n",
    "        random.seed(1)\n",
    "        random.shuffle(ppl)\n",
    "        lp = len(ppl) // 10\n",
    "        ppl = ppl[:lp]\n",
    "        positive_pairs = list(combinations(ppl,2))        \n",
    "        solution_codes_indices = solution_codes.index.to_list()\n",
    "        negative_pairs = []\n",
    "\n",
    "        first_tokenized_code = tokenizer.tokenize(positive_pairs[0][0])\n",
    "        negative_code_scores = bm25.get_scores(first_tokenized_code)\n",
    "        negative_code_ranking = negative_code_scores.argsort()[::-1] # 내림차순\n",
    "        ranking_idx = 0\n",
    "\n",
    "        for solution_code in solution_codes:\n",
    "            negative_solutions = []\n",
    "            while len(negative_solutions) < len(positive_pairs) // len(solution_codes):\n",
    "                high_score_idx = negative_code_ranking[ranking_idx]\n",
    "\n",
    "                if high_score_idx not in solution_codes_indices:\n",
    "                    negative_solutions.append(train_df['code'].iloc[high_score_idx])\n",
    "                ranking_idx += 1\n",
    "\n",
    "            for negative_solution in negative_solutions:\n",
    "                negative_pairs.append((solution_code, negative_solution))\n",
    "\n",
    "        total_positive_pairs.extend(positive_pairs)\n",
    "        total_negative_pairs.extend(negative_pairs)\n",
    "        \n",
    "        temp_len1 = len(total_positive_pairs)\n",
    "        temp_len2 = len(total_negative_pairs)\n",
    "        if temp_len1 > temp_len2:\n",
    "            total_positive_pairs = total_positive_pairs[:temp_len2]\n",
    "        elif temp_len1 < temp_len2:\n",
    "            total_negative_pairs = total_negative_pairs[:temp_len1]\n",
    "        assert len(total_positive_pairs) == len(total_negative_pairs), 'length is different'\n",
    "\n",
    "    pos_code1 = list(map(lambda x:x[0],total_positive_pairs))\n",
    "    pos_code2 = list(map(lambda x:x[1],total_positive_pairs))\n",
    "\n",
    "    neg_code1 = list(map(lambda x:x[0],total_negative_pairs))\n",
    "    neg_code2 = list(map(lambda x:x[1],total_negative_pairs))\n",
    "\n",
    "    pos_label = [1]*len(pos_code1)\n",
    "    neg_label = [0]*len(neg_code1)\n",
    "\n",
    "    pos_code1.extend(neg_code1)\n",
    "    total_code1 = pos_code1\n",
    "    pos_code2.extend(neg_code2)\n",
    "    total_code2 = pos_code2\n",
    "    pos_label.extend(neg_label)\n",
    "    total_label = pos_label\n",
    "    pair_data = pd.DataFrame(data={\n",
    "        'code1':total_code1,\n",
    "        'code2':total_code2,\n",
    "        'similar':total_label})\n",
    "    pair_data = pair_data.sample(frac=1).reset_index(drop=True)\n",
    "    return pair_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2f49c694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [2:04:23<00:00, 24.88s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:21<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = make_fest_dataset(train_df, tokenizer)\n",
    "valid_data = make_dataset(valid_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "760a9b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2599"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[\"code2\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "11d6a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "code1 =[]\n",
    "code2 = []\n",
    "similar = []\n",
    "for i, j, s in zip(train_data[\"code1\"],train_data[\"code2\"], train_data[\"similar\"]):\n",
    "    if not (i.startswith(\"[\")) and not (j.startswith(\"[\")):\n",
    "        code1.append(i)\n",
    "        code2.append(j)\n",
    "        similar.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "36b28177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86666"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(code1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "67828812",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_data = pd.DataFrame({\"code1\":code1, \"code2\":code2, \"similar\":similar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_1(data):\n",
    "    data1 = data.drop_duplicates(\"code1\")\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "625b5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_xdataset(data):\n",
    "    data1 = data.drop_duplicates(\"code1\")\n",
    "    data2 = data.drop_duplicates(\"code2\")\n",
    "    data3 = data.drop_duplicates(\"code1\", keep=\"last\")\n",
    "    data4 = data.drop_duplicates(\"code2\", keep=\"last\")\n",
    "    re_data = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
    "    re_data = re_data.drop_duplicates([\"code1\", \"code2\"])\n",
    "    re_data = re_data.reset_index(drop=True)\n",
    "    return re_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "402a3370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1 = [i for i in range(10)]\\n\\nprint(e1)</td>\n",
       "      <td>x = []\\n\\nfor i in range(10):\\n\\n\\t  x.append(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2 = [i*i for i in range(10)]\\n\\nprint(e2)</td>\n",
       "      <td>x2 = []\\n\\nfor i in range(10):\\n\\n\\t  x2.appen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3 = [i for i in range(10, -1, -1)]\\n\\nprint(e3)</td>\n",
       "      <td>x3 = []\\n\\nfor i in range(10, -1, -1):\\n\\n\\t  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1 = [i for i in [i for i in range(20)] if i %...</td>\n",
       "      <td>f2 = []\\n\\nfor i in range(20):\\n\\n\\t  if i % 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k = [[i for i in range(10)],[i for i in range(...</td>\n",
       "      <td>t = []\\n\\nfor r in range(3):\\n\\n\\t  if r==0:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#same\\n\\nk = [[i for i in range(10)],[i for i ...</td>\n",
       "      <td>t = []\\n\\nfor r in range(3):\\n\\n\\t  if r==0:\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m = {\"col\":1, \"ind\":2}\\n\\nq = {k:v for k,v in ...</td>\n",
       "      <td>t = {}\\n\\nt[\"col\"] =1\\n\\nt[\"ind\"] =2\\n\\nz = {}...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               code1  \\\n",
       "0           e1 = [i for i in range(10)]\\n\\nprint(e1)   \n",
       "1         e2 = [i*i for i in range(10)]\\n\\nprint(e2)   \n",
       "2   e3 = [i for i in range(10, -1, -1)]\\n\\nprint(e3)   \n",
       "3  f1 = [i for i in [i for i in range(20)] if i %...   \n",
       "4  k = [[i for i in range(10)],[i for i in range(...   \n",
       "5  #same\\n\\nk = [[i for i in range(10)],[i for i ...   \n",
       "6  m = {\"col\":1, \"ind\":2}\\n\\nq = {k:v for k,v in ...   \n",
       "\n",
       "                                               code2  similar  \n",
       "0  x = []\\n\\nfor i in range(10):\\n\\n\\t  x.append(...        1  \n",
       "1  x2 = []\\n\\nfor i in range(10):\\n\\n\\t  x2.appen...        1  \n",
       "2  x3 = []\\n\\nfor i in range(10, -1, -1):\\n\\n\\t  ...        1  \n",
       "3  f2 = []\\n\\nfor i in range(20):\\n\\n\\t  if i % 2...        1  \n",
       "4  t = []\\n\\nfor r in range(3):\\n\\n\\t  if r==0:\\n...        0  \n",
       "5  t = []\\n\\nfor r in range(3):\\n\\n\\t  if r==0:\\n...        1  \n",
       "6  t = {}\\n\\nt[\"col\"] =1\\n\\nt[\"ind\"] =2\\n\\nz = {}...        1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = glob(\"D:/meta2/DACON/Code_classification/list_comprehension/ex*py\")\n",
    "ced = {}\n",
    "for c in ce:\n",
    "    re_lines = []\n",
    "    with open(c, \"rt\") as f:\n",
    "        lines = f.readlines()\n",
    "        name = os.path.basename(c).split('.')[0]\n",
    "        for line in lines:\n",
    "            line = line.replace(\"    \",\"\\t\")\n",
    "            re_lines.append(line)\n",
    "        text = \"\\n\".join(re_lines)\n",
    "        ced[name] = text\n",
    "        \n",
    "ced1 = [ced[\"ex1_1\"], ced[\"ex2_1\"], ced[\"ex3_1\"], ced[\"ex4_1\"], ced[\"ex5_1\"], ced[\"ex6_1\"], ced[\"ex7_1\"]]\n",
    "ced2 = [ced[\"ex1_2\"], ced[\"ex2_2\"], ced[\"ex3_2\"], ced[\"ex4_2\"], ced[\"ex5_2\"], ced[\"ex6_2\"], ced[\"ex7_2\"]]\n",
    "\n",
    "add = pd.DataFrame({\"code1\":ced1, \"code2\":ced2, \"similar\":[1, 1, 1, 1, 0, 1, 1]})\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18ed9950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code1</th>\n",
       "      <th>code2</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1 = [i for i in range(10)]\\n\\nprint(e1)</td>\n",
       "      <td>x = []\\n\\nfor i in range(10):\\n\\n\\t  x.append(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2 = [i*i for i in range(10)]\\n\\nprint(e2)</td>\n",
       "      <td>x2 = []\\n\\nfor i in range(10):\\n\\n\\t  x2.appen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3 = [i for i in range(10, -1, -1)]\\n\\nprint(e3)</td>\n",
       "      <td>x3 = []\\n\\nfor i in range(10, -1, -1):\\n\\n\\t  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1 = [i for i in [i for i in range(20)] if i %...</td>\n",
       "      <td>f2 = []\\n\\nfor i in range(20):\\n\\n\\t  if i % 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k = [[i for i in range(10)],[i for i in range(...</td>\n",
       "      <td>t = []\\n\\nfor r in range(3):\\n\\n\\t  if r==0:\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21845896</th>\n",
       "      <td>from operator import mul\\nfrom functools impor...</td>\n",
       "      <td>import math\\nfrom math import gcd\\nINF = float...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21845897</th>\n",
       "      <td>n, d = list(map(int, input().split(' ')))\\nres...</td>\n",
       "      <td>n, m, q = list(map(int, input().split()))\\na=[...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21845898</th>\n",
       "      <td>H,N = list(map(int,input().split()))\\nINF = 10...</td>\n",
       "      <td>import sys\\nN,M = list(map(int,input().split()...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21845899</th>\n",
       "      <td>from collections import defaultdict\\nfrom math...</td>\n",
       "      <td>import math\\ndef main():\\n\\t\\tmod = 1000000007...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21845900</th>\n",
       "      <td>n=int(input())\\nans=1000*((n+999)//1000)-n\\npr...</td>\n",
       "      <td>N = int(input())\\nfor i in range(1,11):\\n\\t\\tn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21845901 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      code1  \\\n",
       "0                  e1 = [i for i in range(10)]\\n\\nprint(e1)   \n",
       "1                e2 = [i*i for i in range(10)]\\n\\nprint(e2)   \n",
       "2          e3 = [i for i in range(10, -1, -1)]\\n\\nprint(e3)   \n",
       "3         f1 = [i for i in [i for i in range(20)] if i %...   \n",
       "4         k = [[i for i in range(10)],[i for i in range(...   \n",
       "...                                                     ...   \n",
       "21845896  from operator import mul\\nfrom functools impor...   \n",
       "21845897  n, d = list(map(int, input().split(' ')))\\nres...   \n",
       "21845898  H,N = list(map(int,input().split()))\\nINF = 10...   \n",
       "21845899  from collections import defaultdict\\nfrom math...   \n",
       "21845900  n=int(input())\\nans=1000*((n+999)//1000)-n\\npr...   \n",
       "\n",
       "                                                      code2  similar  \n",
       "0         x = []\\n\\nfor i in range(10):\\n\\n\\t  x.append(...        1  \n",
       "1         x2 = []\\n\\nfor i in range(10):\\n\\n\\t  x2.appen...        1  \n",
       "2         x3 = []\\n\\nfor i in range(10, -1, -1):\\n\\n\\t  ...        1  \n",
       "3         f2 = []\\n\\nfor i in range(20):\\n\\n\\t  if i % 2...        1  \n",
       "4         t = []\\n\\nfor r in range(3):\\n\\n\\t  if r==0:\\n...        0  \n",
       "...                                                     ...      ...  \n",
       "21845896  import math\\nfrom math import gcd\\nINF = float...        1  \n",
       "21845897  n, m, q = list(map(int, input().split()))\\na=[...        0  \n",
       "21845898  import sys\\nN,M = list(map(int,input().split()...        0  \n",
       "21845899  import math\\ndef main():\\n\\t\\tmod = 1000000007...        1  \n",
       "21845900  N = int(input())\\nfor i in range(1,11):\\n\\t\\tn...        1  \n",
       "\n",
       "[21845901 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.concat([add, train_data], ignore_index=True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a434a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02202c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [46:27<00:00,  9.29s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [01:17<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = make_dataset(train_df, tokenizer)\n",
    "valid_data = make_dataset(valid_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49855e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_data = reduction_xdataset(train_data)\n",
    "valid_pair_data = reduction_dataset(valid_data)\n",
    "# train_pair_data[\"similar\"] = train_pair_data[\"similar\"].map(float)\n",
    "# valid_pair_data[\"similar\"] = valid_pair_data[\"similar\"].map(float)\n",
    "\n",
    "#그냥데이터\n",
    "#3_txt파일 몇개 붙인거\n",
    "#4augmentation\n",
    "#5_1024데이터셋\n",
    "#6_1024_last\n",
    "#7clean_augmentation\n",
    "#8clean_new_augmentation\n",
    "#9clean_new_augmentation_1024\n",
    "#10clean_new_augmentation_2048\n",
    "#11clean_new_augmentation_2048\n",
    "#12 75%\n",
    "#13 n0_print, aug\n",
    "#14 noPorit\n",
    "#15 1026\n",
    "train_pair_data.to_csv(\"D:/code_classification/python3_train15.csv\", index=False)\n",
    "valid_pair_data.to_csv(\"D:/code_classification/python3_valid15.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "56ef19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_pair_data = reduction_dataset(valid_data)\n",
    "train_data[\"similar\"] = train_data[\"similar\"].map(float)\n",
    "valid_pair_data[\"similar\"] = valid_pair_data[\"similar\"].map(float)\n",
    "#그냥데이터\n",
    "#3_txt파일 몇개 붙인거\n",
    "#4augmentation\n",
    "#5_1024데이터셋\n",
    "#6_1024_last\n",
    "#7clean_augmentation\n",
    "#8clean_new_augmentation\n",
    "#9clean_new_augmentation_1024\n",
    "#10clean_new_augmentation_2048\n",
    "#11clean_new_augmentation_2048\n",
    "#12 75%\n",
    "#13 no_print, print_all\n",
    "train_data.to_csv(\"D:/code_classification/python3_train13.csv\", index=False)\n",
    "valid_pair_data.to_csv(\"D:/code_classification/python3_valid13.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "71f1f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_data.to_csv(\"D:/code_classification/python3_train14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9e8c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "df['encode2'] = df['code'].apply(tokenizer.encode)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n",
    "df['encode'] = df['code'].apply(tokenizer.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f399066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if df[\"encode\"].all() == df[\"encode2\"].all():\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a6b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
